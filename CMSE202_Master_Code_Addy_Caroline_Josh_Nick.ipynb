{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tTest-merror:0.349206\n",
      "Will train until Test-merror hasn't improved in 5 rounds.\n",
      "[1]\tTest-merror:0.296296\n",
      "[2]\tTest-merror:0.285714\n",
      "[3]\tTest-merror:0.296296\n",
      "[4]\tTest-merror:0.285714\n",
      "[5]\tTest-merror:0.275132\n",
      "[6]\tTest-merror:0.275132\n",
      "[7]\tTest-merror:0.296296\n",
      "[8]\tTest-merror:0.285714\n",
      "[9]\tTest-merror:0.275132\n",
      "[10]\tTest-merror:0.275132\n",
      "Stopping. Best iteration:\n",
      "[5]\tTest-merror:0.275132\n",
      "\n",
      "\n",
      "\n",
      "% Correct:  93.65079365079364\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Imports for this program are here. Need installs of:\n",
    "\n",
    "xgboost, pandas, numpy, matplotlib, graphviz, sklearn\n",
    "'''\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import graphviz\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "'''\n",
    "Need this data from KenPom website that we have already downloaded\n",
    "in our grithub repository. Import the data and split it into testing\n",
    "and training data based on year. The goal of this split is to use\n",
    "past data (years before 2016) to predict 'future' data (years after 2016).\n",
    "'''\n",
    "\n",
    "full_results = pd.read_csv('full_results.csv')\n",
    "full_stats = pd.read_csv('FullKenPom_pt.csv')\n",
    "\n",
    "###mask test and train data###\n",
    "res_test_mask = (full_results['Year'] == 2016) | (full_results['Year'] == 2017) | (full_results['Year'] == 2018)\n",
    "stats_test_mask = (full_stats['Season'] == 2016) | (full_stats['Season'] == 2017) | (full_stats['Season'] == 2018)\n",
    "res_train_mask = (full_results['Year'] < 2016)\n",
    "stats_train_mask = (full_stats['Season'] < 2016)\n",
    "\n",
    "res_data_test = full_results[res_test_mask]\n",
    "stats_data_test = full_stats[stats_test_mask]\n",
    "res_data_train = full_results[res_train_mask]\n",
    "stats_data_train = full_stats[stats_train_mask]\n",
    "\n",
    "#reindex all of them\n",
    "res_data_test = res_data_test.reset_index()\n",
    "stats_data_test = stats_data_test.reset_index()\n",
    "res_data_train = res_data_train.reset_index()\n",
    "stats_data_train = stats_data_train.reset_index()\n",
    "\n",
    "for i in range(len(res_data_test)):\n",
    "    if res_data_test['Region Name'][i] == \"First Four\":\n",
    "        res_data_test = res_data_test.drop(i)\n",
    "for i in range(len(res_data_train)):\n",
    "    if res_data_train['Region Name'][i] == \"First Four\":\n",
    "        res_data_train = res_data_train.drop(i)\n",
    "        \n",
    "#reindex all of them\n",
    "res_data_test = res_data_test.reset_index()\n",
    "stats_data_test = stats_data_test.reset_index()\n",
    "res_data_train = res_data_train.reset_index()\n",
    "stats_data_train = stats_data_train.reset_index()\n",
    "\n",
    "\n",
    "#these names match the kenpom stats csv\n",
    "stats_vec = [\"AdjTempo\",\n",
    "            \"AdjOE\",\n",
    "            \"AdjDE\",\n",
    "            \"AdjEM\",\n",
    "            \"seed\",\n",
    "            \"ConfTournament\",\n",
    "            \"SOSAdjEM\",\n",
    "            \"NCSOSAdjEM\",\n",
    "            \"O-D_eFG_Pct\",\n",
    "            \"D-O_TO_Pct\",\n",
    "            \"O-D_OR_Pct\",\n",
    "            \"O-D_FT_Rate\",\n",
    "            \"LastTenRecord\"]\n",
    "\n",
    "# Move training data into 2 numpy arrays - data and labels (results)\n",
    "N = len(res_data_train)\n",
    "\n",
    "training_data = np.zeros((N,13))\n",
    "training_labels = np.zeros((N,1))\n",
    "\n",
    "for i in range(len(res_data_train)):\n",
    "    year = res_data_train['Year'][i]\n",
    "    teamA = res_data_train['TeamA'][i]\n",
    "    teamB = res_data_train['TeamB'][i]\n",
    "    score_diff = res_data_train['ScoreA'][i] - res_data_train['ScoreB'][i]\n",
    "    for k in range(len(stats_data_train)):\n",
    "        if ((stats_data_train['Season'][k] == year) and (stats_data_train['TeamName'][k] == teamA)):\n",
    "            indexA = k\n",
    "            break\n",
    "            \n",
    "    for k in range(len(stats_data_train)):\n",
    "        if ((stats_data_train['Season'][k] == year) and (stats_data_train['TeamName'][k] == teamB)):\n",
    "            indexB = k\n",
    "            break\n",
    "    for s in range(len(stats_vec)):\n",
    "        stat = stats_vec[s]\n",
    "        training_data[i][s] = stats_data_train[stat][indexA] - stats_data_train[stat][indexB]\n",
    "    \n",
    "    if (score_diff > 0):\n",
    "        training_labels[i][0] = 1\n",
    "    else:\n",
    "        training_labels[i][0] = 0\n",
    "\n",
    "# Move testing data into 2 numpy arrays - data and labels (results)\n",
    "N = len(res_data_test)\n",
    "\n",
    "testing_data = np.zeros((N,13))\n",
    "testing_labels = np.zeros((N,1))\n",
    "\n",
    "for i in range(len(res_data_test)):\n",
    "    year = res_data_test['Year'][i]\n",
    "    teamA = res_data_test['TeamA'][i]\n",
    "    teamB = res_data_test['TeamB'][i]\n",
    "    score_diff = res_data_test['ScoreA'][i] - res_data_test['ScoreB'][i]\n",
    "    for k in range(len(stats_data_test)):\n",
    "        if ((stats_data_test['Season'][k] == year) and (stats_data_test['TeamName'][k] == teamA)):\n",
    "            indexA = k\n",
    "            break\n",
    "            \n",
    "    for k in range(len(stats_data_test)):\n",
    "        if ((stats_data_test['Season'][k] == year) and (stats_data_test['TeamName'][k] == teamB)):\n",
    "            indexB = k\n",
    "            break\n",
    "    for s in range(len(stats_vec)):\n",
    "        stat = stats_vec[s]\n",
    "        testing_data[i][s] = stats_data_test[stat][indexA] - stats_data_test[stat][indexB]\n",
    "    \n",
    "    if (score_diff > 0):\n",
    "        testing_labels[i][0] = 1\n",
    "    else:\n",
    "        testing_labels[i][0] = 0\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "This next section of code is for normalizing the data (if you want\n",
    "since xgboost does not need the data to be normalized)\n",
    "'''\n",
    "\n",
    "\n",
    "#Time to normalize the data\n",
    "training_data = preprocessing.normalize(training_data, axis=0, norm='max')\n",
    "testing_data = preprocessing.normalize(testing_data, axis=0, norm='max')\n",
    "\n",
    "evallist = [(testing_data, 'eval'), (training_data, 'train')]\n",
    "\n",
    "param = {'objective': 'multi:softprob'}\n",
    "param['eval_metric'] = \"merror\"\n",
    "param['num_class'] = 2\n",
    "\n",
    "dtrain = xgb.DMatrix(training_data, label=training_labels,\n",
    "                     feature_names=stats_vec)\n",
    "dtest = xgb.DMatrix(testing_data, label=testing_labels,\n",
    "                    feature_names=stats_vec)\n",
    "\n",
    "\n",
    "'''\n",
    "The next three parts (labeled 'Phases') are for tuning the model\n",
    "for creating the best possible paramters for the final model.\n",
    "'''\n",
    "\n",
    "#Phase 1: Tuning Max depth and min_child_weight\n",
    "param = {'objective': 'multi:softprob'}\n",
    "param['eval_metric'] = \"merror\"\n",
    "param['num_class'] = 2  # 2 classes - win or loss\n",
    "\n",
    "num_round = 999 #looks like it levels off at around 200\n",
    "\n",
    "gridsearch_params = [\n",
    "    (max_depth, min_child_weight)\n",
    "    for max_depth in range(1,8)\n",
    "    for min_child_weight in range(1,6)\n",
    "]\n",
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for max_depth, min_child_weight in gridsearch_params:\n",
    "    # print(\"CV with max_depth={}, min_child_weight={}\".format(\n",
    "    #                         max_depth,\n",
    "    #                         min_child_weight))\n",
    "    \n",
    "    # Update Parameters\n",
    "    param['max_depth'] = max_depth\n",
    "    param['min_child_weight'] = min_child_weight\n",
    "    \n",
    "    #Run CV\n",
    "    cv_results = xgb.cv(param,\n",
    "                        dtrain,\n",
    "                        num_boost_round=num_round, #maybe wrong\n",
    "                        seed=42,\n",
    "                        nfold=3,\n",
    "                        metrics={'merror'},\n",
    "                        early_stopping_rounds=10)\n",
    "    \n",
    "    #Update best MError\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    # boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    # print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (max_depth, min_child_weight)\n",
    "    \n",
    "\n",
    "param['max_depth'] = best_params[0]\n",
    "param['min_child_weight'] = best_params[1]\n",
    "\n",
    "#Phase 2: Subsample and Colsample_bytree\n",
    "#tune subsample,colsample\n",
    "gridsearch_params = [\n",
    "    (subsample, colsample)\n",
    "    for subsample in [i/10. for i in range(1,11)]\n",
    "    for colsample in [i/10. for i in range(1,11)]\n",
    "]\n",
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for subsample, colsample in reversed(gridsearch_params):\n",
    "    # print(\"CV with subsample={}, colsample={}\".format(\n",
    "    #                         subsample,\n",
    "    #                         colsample))\n",
    "    # Update our parameters\n",
    "    param['subsample'] = subsample\n",
    "    param['colsample_bytree'] = colsample\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=num_round,\n",
    "        seed=42,\n",
    "        nfold=3,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best Merror\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    # boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    # print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = (subsample,colsample)\n",
    "        \n",
    "        \n",
    "param['subsample'] = best_params[0]\n",
    "param['colsample_bytree'] = best_params[1]\n",
    "\n",
    "#Phase 3: eta\n",
    "min_merror = float(\"Inf\")\n",
    "best_params = None\n",
    "for eta in [0.5,0.3, 0.03, .003,0.0003]:\n",
    "    # print(\"CV with eta={}\".format(eta))\n",
    "    # Update our parameters\n",
    "    param['eta'] = eta\n",
    "    # Run CV\n",
    "    cv_results = xgb.cv(\n",
    "        param,\n",
    "        dtrain,\n",
    "        num_boost_round=num_round,\n",
    "        seed=42,\n",
    "        nfold=3,\n",
    "        metrics={'merror'},\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "    # Update best Merror\n",
    "    mean_merror = cv_results['test-merror-mean'].min()\n",
    "    boost_rounds = cv_results['test-merror-mean'].idxmin()\n",
    "    # boost_rounds = cv_results['test-merror-mean'].argmin()\n",
    "    # print(\"\\tMerror {} for {} rounds\".format(mean_merror, boost_rounds))\n",
    "    if mean_merror < min_merror:\n",
    "        min_merror = mean_merror\n",
    "        best_params = eta\n",
    "        \n",
    "param['eta'] = best_params\n",
    "\n",
    "\n",
    "'''\n",
    "This section is for the final model for predicting results. Here we test the\n",
    "model (trained against the data between 2006-2015) with the known results of\n",
    "the 2016-2018 seasons. The plot showing the best parameters is commented out\n",
    "for your convience, as well as the results of the correct values.\n",
    "'''\n",
    "\n",
    "final_gb = xgb.train(param,dtrain,num_boost_round=num_round,\n",
    "                   early_stopping_rounds=5,evals=[(dtest, \"Test\")])\n",
    "\n",
    "# xgb.plot_importance(final_gb)\n",
    "\n",
    "ypred = final_gb.predict(dtest)\n",
    "ypred\n",
    "\n",
    "correct_list = np.zeros_like(testing_labels)\n",
    "for i in range(len(ypred)):\n",
    "    if ypred[i][0] < ypred[i][1]:\n",
    "        metric = 1 # team A predicted to win\n",
    "    else:\n",
    "        metric = 0\n",
    "    correct_list[i][0] = metric\n",
    "    # print(\"TeamA Win% {:.4}  SeedDiff {}\".format(ypred[i][1]*100,testing_data[i][4]*-1))\n",
    "\n",
    "print('\\n')\n",
    "print(\"% Correct: \", (correct_list.sum() / len(correct_list))*100)\n",
    "print('\\n')\n",
    "\n",
    "# xgb.plot_tree(final_gb)\n",
    "# fig = plt.gcf()\n",
    "# fig.set_size_inches(18,25)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
